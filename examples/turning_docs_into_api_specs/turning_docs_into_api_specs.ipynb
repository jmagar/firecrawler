{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericciarla/projects/python_projects/agents_testing/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from firecrawl import FirecrawlApp\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "firecrawl_api_key = os.getenv(\"FIRECRAWL_API_KEY\")\n",
    "\n",
    "# Configure the Google Generative AI module with the API key\n",
    "genai.configure(api_key=google_api_key)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro-001\")\n",
    "\n",
    "# Set the docs URL\n",
    "docs_url=\"https://docs.firecrawl.dev\"\n",
    "\n",
    "# Initialize the FirecrawlApp with your API key\n",
    "app = FirecrawlApp(api_key=firecrawl_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# Crawl all pages on docs\n",
    "params = {\n",
    "    \"pageOptions\": {\n",
    "        \"onlyMainContent\": True\n",
    "    },\n",
    "}\n",
    "crawl_result = app.crawl_url(docs_url, params=params)\n",
    "\n",
    "print(len(crawl_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_instructions = f\"\"\"Given the following API documentation content, generate an OpenAPI 3.0 specification in JSON format ONLY if you are 100% confident and clear about all details. Focus on extracting the main endpoints, their HTTP methods, parameters, request bodies, and responses. The specification should follow OpenAPI 3.0 structure and conventions. Include only the 200 response for each endpoint. Limit all descriptions to 5 words or less.\n",
    "\n",
    "If there is ANY uncertainty, lack of complete information, or if you are not 100% confident about ANY part of the specification, return an empty JSON object {{}}.\n",
    "\n",
    "Do not make anything up. Only include information that is explicitly provided in the documentation. If any detail is unclear or missing, do not attempt to fill it in.\n",
    "\n",
    "API Documentation Content:\n",
    "{{content}}\n",
    "\n",
    "Generate the OpenAPI 3.0 specification in JSON format ONLY if you are 100% confident about every single detail. Include only the JSON object, no additional text, and ensure it has no errors in the JSON format so it can be parsed. Remember to include only the 200 response for each endpoint and keep all descriptions to 5 words maximum.\n",
    "\n",
    "Once again, if there is ANY doubt, uncertainty, or lack of complete information, return an empty JSON object {{}}.\n",
    "\n",
    "To reiterate: accuracy is paramount. Do not make anything up. If you are not 100% clear or confident about the entire OpenAPI spec, return an empty JSON object {{}}.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API specification saved to docs.firecrawl.dev/api_spec_0.json\n",
      "API specification saved to docs.firecrawl.dev/api_spec_1.json\n",
      "API specification saved to docs.firecrawl.dev/api_spec_2.json\n",
      "API specification saved to docs.firecrawl.dev/api_spec_3.json\n",
      "API specification saved to docs.firecrawl.dev/api_spec_4.json\n",
      "An error occurred for page 5: 'content'\n",
      "No API specification found for page 6\n",
      "API specification saved to docs.firecrawl.dev/api_spec_7.json\n",
      "No API specification found for page 8\n",
      "No API specification found for page 9\n",
      "API specification saved to docs.firecrawl.dev/api_spec_10.json\n",
      "No API specification found for page 11\n",
      "No API specification found for page 12\n",
      "API specification saved to docs.firecrawl.dev/api_spec_13.json\n",
      "No API specification found for page 14\n",
      "No API specification found for page 15\n",
      "No API specification found for page 16\n",
      "No API specification found for page 17\n",
      "No API specification found for page 18\n",
      "No API specification found for page 19\n",
      "No API specification found for page 20\n",
      "No API specification found for page 21\n",
      "No API specification found for page 22\n",
      "No API specification found for page 23\n",
      "No API specification found for page 24\n",
      "No API specification found for page 25\n",
      "No API specification found for page 26\n",
      "No API specification found for page 27\n",
      "No API specification found for page 28\n",
      "No API specification found for page 29\n",
      "No API specification found for page 30\n",
      "No API specification found for page 31\n",
      "No API specification found for page 32\n",
      "No API specification found for page 33\n",
      "No API specification found for page 34\n",
      "No API specification found for page 35\n",
      "Total API specifications collected: 8\n"
     ]
    }
   ],
   "source": [
    "# Create a folder for storing API specs\n",
    "import os\n",
    "import urllib.parse\n",
    "\n",
    "folder_name = urllib.parse.urlparse(docs_url).netloc\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Initialize a list to store all API specs\n",
    "all_api_specs = []\n",
    "\n",
    "# Process each page in crawl_result\n",
    "for index, result in enumerate(crawl_result):\n",
    "    if 'content' in result:\n",
    "        # Update prompt_instructions with the current page's content\n",
    "        current_prompt = prompt_instructions.replace(\"{content}\", result['content'])\n",
    "        try:\n",
    "            # Query the model\n",
    "            response = model.generate_content([current_prompt])\n",
    "            response_dict = response.to_dict()\n",
    "            response_text = response_dict['candidates'][0]['content']['parts'][0]['text']\n",
    "            \n",
    "            # Remove the ```json code wrap if present\n",
    "            response_text = response_text.strip().removeprefix('```json').removesuffix('```').strip()\n",
    "            \n",
    "            # Parse JSON\n",
    "            json_data = json.loads(response_text)\n",
    "            \n",
    "            # Save non-empty API specs\n",
    "            if json_data != {}:\n",
    "                output_file = os.path.join(folder_name, f'api_spec_{index}.json')\n",
    "                with open(output_file, 'w') as f:\n",
    "                    json.dump(json_data, f, indent=2, sort_keys=True)\n",
    "                print(f\"API specification saved to {output_file}\")\n",
    "                \n",
    "                # Add the API spec to the list\n",
    "                all_api_specs.append(json_data)\n",
    "            else:\n",
    "                print(f\"No API specification found for page {index}\")\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON response for page {index}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for page {index}: {str(e)}\")\n",
    "\n",
    "# Print the total number of API specs collected\n",
    "print(f\"Total API specifications collected: {len(all_api_specs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined API specification saved to docs.firecrawl.dev/combined_api_spec.json\n",
      "Total paths in combined spec: 8\n",
      "Total schemas in combined spec: 0\n"
     ]
    }
   ],
   "source": [
    "# Combine all API specs and keep the most filled out spec for each path and method\n",
    "combined_spec = {\n",
    "    \"openapi\": \"3.0.0\",\n",
    "    \"info\": {\n",
    "        \"title\": f\"{docs_url} API Specification\",\n",
    "        \"version\": \"1.0.0\"\n",
    "    },\n",
    "    \"paths\": {},\n",
    "    \"components\": {\n",
    "        \"schemas\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "def count_properties(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return sum(count_properties(v) for v in obj.values()) + len(obj)\n",
    "    elif isinstance(obj, list):\n",
    "        return sum(count_properties(item) for item in obj)\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "for spec in all_api_specs:\n",
    "    if \"paths\" in spec:\n",
    "        for path, methods in spec[\"paths\"].items():\n",
    "            if path not in combined_spec[\"paths\"]:\n",
    "                combined_spec[\"paths\"][path] = {}\n",
    "            for method, details in methods.items():\n",
    "                if method not in combined_spec[\"paths\"][path] or count_properties(details) > count_properties(combined_spec[\"paths\"][path][method]):\n",
    "                    combined_spec[\"paths\"][path][method] = details\n",
    "\n",
    "    if \"components\" in spec and \"schemas\" in spec[\"components\"]:\n",
    "        for schema_name, schema in spec[\"components\"][\"schemas\"].items():\n",
    "            if schema_name not in combined_spec[\"components\"][\"schemas\"] or count_properties(schema) > count_properties(combined_spec[\"components\"][\"schemas\"][schema_name]):\n",
    "                combined_spec[\"components\"][\"schemas\"][schema_name] = schema\n",
    "\n",
    "# Save the combined API spec\n",
    "output_file = os.path.join(folder_name, 'combined_api_spec.json')\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(combined_spec, f, indent=2, sort_keys=True)\n",
    "\n",
    "print(f\"Combined API specification saved to {output_file}\")\n",
    "print(f\"Total paths in combined spec: {len(combined_spec['paths'])}\")\n",
    "print(f\"Total schemas in combined spec: {len(combined_spec['components']['schemas'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# note: turn this into a simple web app like roast my site\n",
    "- select which methods you want to add\n",
    "- generate a UI for each method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
