# ===================================
# Firecrawl Environment Configuration
# ===================================
# This is an example configuration file. Copy to .env and update values as needed.
# Sensitive values should be stored in .env.local (not tracked in git).

# ===== Core Service Configuration =====
NUM_WORKERS_PER_QUEUE=16
PORT=3002
HOST=0.0.0.0

# ===== Redis Configuration =====
# For self-hosting using docker: redis://redis:6379
# For local development: redis://localhost:6379
REDIS_URL=redis://redis:6379
REDIS_RATE_LIMIT_URL=redis://redis:6379

# ===== Playwright Service =====
PLAYWRIGHT_MICROSERVICE_URL=http://playwright-service:3000/scrape

# ===== LLM Configuration =====
# Add your OpenAI API key for LLM-dependent features (image alt generation, etc.)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here
MODEL_NAME=gpt-4o

# ===== Vector Search & Embeddings (TEI) =====
# Text Embeddings Inference service configuration
TEI_URL=http://localhost:8080
TEI_API_KEY=
ENABLE_VECTOR_STORAGE=true
VECTOR_STORAGE_ASYNC=true
MIN_SIMILARITY_THRESHOLD=0.6
# Model for embeddings - use sentence-transformers models for TEI
MODEL_EMBEDDING_NAME=sentence-transformers/all-MiniLM-L6-v2
# Vector dimension (384 for MiniLM, 1024 for Qwen 0.6B)
VECTOR_DIMENSION=384
MAX_EMBEDDING_CONTENT_LENGTH=200000

# ===== Authentication =====
BULL_AUTH_KEY=

# ===== Fire Engine Configuration =====
# Set if using the Fire Engine closed beta
# FIRE_ENGINE_BETA_URL=

# ===== Media & Performance =====
# Block media requests to save proxy bandwidth
BLOCK_MEDIA=false

# ===== Webhook Configuration =====
# For self-hosted version webhook callbacks
# SELF_HOSTED_WEBHOOK_URL=

# ===== Logging Configuration =====
# Levels: NONE, ERROR, WARN, INFO, DEBUG, TRACE
LOGGING_LEVEL=INFO

# ===== System Monitoring =====
# Disable RAM/CPU load checks (1.0 = disabled)
MAX_CPU=1.0
MAX_RAM=1.0

# ===== SearchNG Integration =====
# Configure SearchNG service for enhanced search capabilities
SEARXNG_ENDPOINT=
SEARXNG_ENGINES=google,bing,duckduckgo
SEARXNG_CATEGORIES=general

# ===== Language Filtering =====
# Set to language code (e.g., 'en', 'es', 'fr') or 'all' to disable
DEFAULT_CRAWL_LANGUAGE=en

# ===== MCP Server Configuration =====
# Only used when running the MCP server directly (apps/firecrawler)
FIRECRAWL_API_URL=http://localhost:3002
FIRECRAWLER_HOST=localhost
FIRECRAWLER_PORT=8000
FIRECRAWLER_TRANSPORT=streamable-http

# ===== MCP Server Advanced Settings =====
# These are optional and have sensible defaults
FIRECRAWLER_LOG_LEVEL=INFO
FIRECRAWLER_LOG_TO_FILE=true
FIRECRAWLER_MAX_CONCURRENT=20
FIRECRAWLER_REQUEST_TIMEOUT=15
FIRECRAWLER_RATE_LIMIT_RPM=100
FIRECRAWLER_RATE_LIMIT_RPH=1000
FIRECRAWLER_ENABLE_RATE_LIMIT=false
FIRECRAWLER_DEFAULT_LLM_MODEL=gpt-4o
FIRECRAWLER_LLM_MAX_TOKENS=1000
FIRECRAWLER_VECTOR_SEARCH_LIMIT=10
FIRECRAWLER_VECTOR_SIMILARITY_THRESHOLD=0.6

# ===== Development & Testing =====
# Only for development environments
FIRECRAWLER_DEV_MODE=false
FIRECRAWLER_DEBUG=false
FIRECRAWLER_TEST_MODE=false

# ===================================
# DEPLOYMENT NOTES
# ===================================
#
# LOCAL DEVELOPMENT:
# 1. Copy this file: cp .env.example .env
# 2. Update API keys and endpoints for your environment
# 3. For Docker Compose: docker-compose up
# 4. For MCP server: python -m firecrawl_mcp.server
#
# PRODUCTION:
# 1. Use .env.local for sensitive values (not tracked in git)
# 2. Set appropriate rate limits and timeouts
# 3. Enable authentication where needed
# 4. Configure proper logging levels
# 5. Set up monitoring and alerting
#
# SECURITY:
# - Never commit real API keys to version control
# - Rotate keys regularly
# - Use environment-specific configurations
# - Enable rate limiting in production